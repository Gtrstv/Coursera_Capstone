{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('PythonIBM': conda)",
   "metadata": {
    "interpreter": {
     "hash": "11eb7b0514ce6e3bb9188e244fe3baf58be06a5316edc0531cae52557ede83c1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h1 align=\"center\">Coursera IBM Capstone Project - Applied Data Science</h1>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    " <h2 align=\"center\">Prepared by Stephan G. Maher</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3 align=\"center\">Part 1 WEEK3 Final Assignment</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>I''m providing these markdown notes, but there is also comments for most cells </h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages for scrape,Geo Data and set pandas options\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import json # library to handle JSON files\n",
    "import requests # library to handle requests\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "import geocoder\n",
    "#Import libraries for Clustering\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.cluster import KMeans\n",
    "#Import geocoder to get location of Toronto\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "#Import Folium to create map.\n",
    "import folium\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>.prompt { display:none !important; }</style>\"))"
   ]
  },
  {
   "source": [
    "#### 1. Scrape Webiste and prepare initial Data Frame"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify web page  to be scraped, parse the HTML and reformat\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\"\n",
    "page = urllib.request.urlopen(url)\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "# print(soup.prettify) #uncomment to see raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the title of table\n",
    "soup.title\n",
    "soup.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull wikitable sortable into a variable\n",
    "my_table=soup.find('table', class_='wikitable sortable')\n",
    "#my_table # un-comment to see raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create lists of column data\n",
    "A=[]\n",
    "B=[]\n",
    "C=[]\n",
    "for row in my_table.findAll('tr'):\n",
    "    cells=row.findAll('td')\n",
    "    if len(cells)==3:\n",
    "        A.append(cells[0].find(text=True))\n",
    "        B.append(cells[1].find(text=True))\n",
    "        C.append(cells[2].find(text=True))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjust lists to remove /n\n",
    "a=[a[:-1] for a in A]\n",
    "b=[b[:-1] for b in B]\n",
    "c=[c[:-1] for c in C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base dataframe\n",
    "# after this step perform data cleaning for df\n",
    "df=pd.DataFrame(a,columns=['Postal Code'])\n",
    "df['Borough']=b\n",
    "df['Neighborhood']=c\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "source": [
    "<h3>Cleaning df Steps</h3>\n",
    "<h3>1 discard Not assigned Boroughs </h3>\n",
    "<h3>2 duplicate postal codes with different neighborhoods should be combined into 1 postal code and a comma seperated list of Neighborhoods </h3>\n",
    "<h3>3 If the neigborhood is Not Assigned, use the Borough Assignment </h3>\n",
    "<h3>4 Create the shape of the final df </h3>\n",
    "<h3>5 Submit workbook to Github </h3>\n",
    "<h3> </h3>\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 discard empty Borough rows\n",
    "print(df.shape) #(180,3)\n",
    "print(df['Borough'].value_counts()) #77 Not Assigned\n",
    "df['Borough'].replace('Not assigned',np.nan,inplace=True)\n",
    "df.dropna(subset=[\"Borough\"], axis=0, inplace=True)\n",
    "df['Postal Code'].sort_values()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "#print(df.head(10))\n",
    "#df.shape #S/b 180-77 reindex shape(103,3)"
   ]
  },
  {
   "source": [
    "<h3>A review of the data shows that there are 77 Boroughs Not Assigned </h3>\n",
    "<h3>The initial shape (180,3> is adjusted by removing those 77 Boroughs </h3>\n",
    "<h3>The final shape is (103,3) as displayed below along with the dataframe </h3>\n",
    "<h3> a review of data shows no other cleaning steps are needed. </h3>\n",
    "<h3> </h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3 align=\"center\"> Submit Week3Final Question 1</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "source": [
    "<h2 align=\"center\">Start Question 2 </h2>\n",
    "<h3>1 create the function get_Geocode that will pull 'latitude' and 'longitude' for the submitted 'Postal Code' </h3>\n",
    "<h3>2 create a function call that reads the df dataframe and submits each postal code and stores the codes and latitude, longitude info to series. </h3>\n",
    "<h3>3 insert the series information to a dataframe df_geo </h3>\n",
    "<h3> </h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#Function to pull Geo Data by Postal Code(PC)\n",
    "\n",
    "def get_Geocode(PC):\n",
    "    lat_lng_coords = None\n",
    "    i=0\n",
    "    while (lat_lng_coords is None):\n",
    "        g=geocoder.arcgis('{},Toronto, Ontario'.format(PC))\n",
    "        lat_lng_coords = g.latlng\n",
    "        i+=1\n",
    "        if i > 70:\n",
    "            return None\n",
    "        else:      \n",
    "            return lat_lng_coords\n",
    "    \n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through df Postal Codes and collect Lat long data\n",
    "A=[]\n",
    "B=[]\n",
    "C=[]\n",
    "for PC in df['Postal Code']:\n",
    "    LL=get_Geocode(PC)\n",
    "    if LL is None:\n",
    "        print(\"Error\")\n",
    "        break\n",
    "    else:\n",
    "        A.append(PC)\n",
    "        B.append(LL[0])\n",
    "        C.append(LL[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo=pd.DataFrame(A,columns=['Postal Code'])\n",
    "df_geo['Latitude']=B\n",
    "df_geo['Longitude']=C\n",
    "print(df_geo.shape)\n",
    "print(df_geo.head(10))"
   ]
  },
  {
   "source": [
    "<h3>The steps above run the geo-coder and pull the Latitude and longitude for each zip code</h3>\n",
    "<h3>There aren't seperate Latitude and longitude for each neighborhood, but there are for each borough </h3>\n",
    "<h3>I plan to use the Boroughs in Toronto City proper and rename them to neighborhoods </h3>\n",
    "<h3>This leads to 4 boroughs which I will use as centriods </h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>1 Sort the Original Dataframe and the Geo dataframe by Postal Code </h3>\n",
    "<h3>2 merge the dataframes by matching Postal Codes </h3>\n",
    "<h3>3 Print Question2 Dataframe head</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the dataframes by postal code\n",
    "df.sort_values(['Postal Code'])\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df_geo.sort_values(['Postal Code'])\n",
    "df_geo.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "source": [
    "<h3>Show dataframe needed for Question2 </h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to join the geographical columns from csv to project df by \"Postal Code\"\n",
    "col = ['Postal Code']\n",
    "df=df.join(df_geo.set_index(col), on=col)\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "source": [
    "<h2 align=\"center\"> Submit Week3Final Question 2</h2>\n",
    "<h2 align=\"center\">See Shape and head above</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h2 align=\"center\">Question 3 Analyse Toronto neighborhood</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>I'm selecting the Boroughs inside the city limits of Toronto </h3>\n",
    "<h3>I then create the datafeame 'Toronto_Data' which exlcudes the neigborhoods outside of Toronto </h3>\n",
    "<h3>Finally I rename the 'Borough' column to 'neighborhood' </h3>\n",
    "<h3>Individual Neigborhoods would have the same(duplicate) postal code </h3>\n",
    "<h3>Each Borough has a unique Postal Code</h3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Boroughs in Toronto and change the description to neighborhood\n",
    "Toronto_data = df[['Postal Code','Borough','Latitude','Longitude']]\n",
    "Toronto_data = Toronto_data[Toronto_data['Borough'].str.contains('Toronto')].reset_index(drop=True)\n",
    "Toronto_data = Toronto_data.rename(columns={'Borough':'neighborhood'})\n",
    "print(Toronto_data.head())\n",
    "print(Toronto_data.shape)\n",
    "uniqueValues = Toronto_data['neighborhood'].unique()\n",
    "print(uniqueValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get city coordinates for map background\n",
    "address = 'Toronto, Ontario'\n",
    "geolocator = Nominatim(user_agent=\"Tor_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinates of Toronto are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the map and plot all current data points by Borough in the City\n",
    "Toranto_map = folium.Map(location=[latitude, longitude], zoom_start=10)\n",
    "\n",
    "#Plot the neighbourhoods\n",
    "for lat, lng, postal_code, neighborhood in zip(Toronto_data['Latitude'], Toronto_data['Longitude'], Toronto_data['neighborhood'], Toronto_data['Postal Code']):\n",
    "    label = '{}, {}'.format(postal_code, neighborhood)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(Toranto_map)  \n",
    "Toranto_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "CLIENT_ID = 'QXBRRBOS22KLNITA013HBQPZ0ZQ5EPT3QQY4P5BVWF3EGJPS' # your Foursquare ID\n",
    "CLIENT_SECRET = '5OXNVM4M2C11UDXGAKVNCHNY5GXCPRAXMMYDC1VUOKBL0RWQ' # your Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version\n",
    "LIMIT = 100 # A default Foursquare API limit value"
   ]
  },
  {
   "source": [
    "<h3> This section will get venue information near each data point so we can use this data to cluster</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get venues within 500 meters of Neighborhood locations\n",
    "LIMIT = 100 # limit Foursquare API\n",
    "radius = 500 # define radius\n",
    "# create URL\n",
    "url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "    CLIENT_ID, \n",
    "    CLIENT_SECRET, \n",
    "    VERSION, \n",
    "    latitude, \n",
    "    longitude, \n",
    "    radius, \n",
    "    LIMIT)\n",
    "#url # display URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the result Data\n",
    "results = requests.get(url).json()\n",
    "#results #uncomment this line to see raw JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that extracts the category of the venue\n",
    "def get_category_type(row):\n",
    "    try:\n",
    "        categories_list = row['categories']\n",
    "    except:\n",
    "        categories_list = row['venue.categories']\n",
    "        \n",
    "    if len(categories_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return categories_list[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy Category function\n",
    "# function that extracts the category of the venue\n",
    "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighborhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get and normalize venues\n",
    "venues = results['response']['groups'][0]['items']\n",
    "    \n",
    "nearby_venues = json_normalize(venues) # flatten JSON\n",
    "\n",
    "# filter columns\n",
    "filtered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\n",
    "nearby_venues =nearby_venues.loc[:, filtered_columns]\n",
    "\n",
    "# filter the category for each row\n",
    "nearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n",
    "\n",
    "# clean columns\n",
    "nearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n",
    "\n",
    "nearby_venues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call Function and run against our neighborhood list\n",
    "Toronto_venues = getNearbyVenues(names=Toronto_data['neighborhood'],\n",
    "                                   latitudes=Toronto_data['Latitude'],\n",
    "                                   longitudes=Toronto_data['Longitude']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print information about neigborhood venues\n",
    "print(Toronto_venues.shape)\n",
    "print(Toronto_venues.head())\n",
    "print(Toronto_venues.groupby('Neighborhood').count())\n",
    "print('There are {} uniques categories.'.format(len(Toronto_venues['Venue Category'].unique())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "Toronto_onehot = pd.get_dummies(Toronto_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add neighborhood column back to dataframe\n",
    "Toronto_onehot['Neighborhood'] = Toronto_venues['Neighborhood'] \n",
    "\n",
    "# move neighborhood column to the first column\n",
    "fixed_columns = [Toronto_onehot.columns[-1]] + list(Toronto_onehot.columns[:-1])\n",
    "Toronto_onehot = Toronto_onehot[fixed_columns]\n",
    "print(Toronto_onehot.shape)\n",
    "Toronto_grouped = Toronto_onehot.groupby('Neighborhood').mean().reset_index()\n",
    "print(Toronto_grouped.shape)\n",
    "#Toronto_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get top 5 venues per Neighborhood\n",
    "num_top_venues = 5\n",
    "for hood in Toronto_grouped['Neighborhood']:\n",
    "    print(\"----\"+hood+\"----\")\n",
    "    temp = Toronto_grouped[Toronto_grouped['Neighborhood'] == hood].T.reset_index()\n",
    "    temp.columns = ['venue','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 2})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 10\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "# create columns according to number of top venues\n",
    "columns = ['Neighborhood']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "neighborhoods_venues_sorted = pd.DataFrame(columns=columns)\n",
    "neighborhoods_venues_sorted['Neighborhood'] = Toronto_grouped['Neighborhood']\n",
    "\n",
    "for ind in np.arange(Toronto_grouped.shape[0]):\n",
    "    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(Toronto_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "neighborhoods_venues_sorted.head(4)"
   ]
  },
  {
   "source": [
    "<h3>Above is the dataframe of the venues that we will use for  K-means,/h3>\n",
    "<h3> </h3>\n",
    "<h2 align=\"center\">Starting Clustering </h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>1 Set the number of centroids and kmeans algorythm </h3>\n",
    "<h3>2 Add the clustering labels = venues by neighborhood </h3>\n",
    "<h3>3 Create a map of the data </h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of clusters\n",
    "kmc = 4\n",
    "\n",
    "Toronto_grouped_clustering = Toronto_grouped.drop('Neighborhood', 1)\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kmc, random_state=6).fit(Toronto_grouped_clustering)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add clustering labels\n",
    "neighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n",
    "\n",
    "Toronto_merged = Toronto_data\n",
    "\n",
    "# merge Toronto_grouped with Toronto_data to add latitude/longitude for each neighborhood\n",
    "Toronto_merged = Toronto_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='neighborhood')\n",
    "\n",
    "Toronto_merged.head() # check the last columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      # create map\n",
    "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kmc)\n",
    "ys = [i + x + (i*x)**2 for i in range(kmc)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(Toronto_merged['Latitude'], Toronto_merged['Longitude'], Toronto_merged['neighborhood'], Toronto_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "map_clusters"
   ]
  },
  {
   "source": [
    "<h3>The final four frames show the Most common locations for each cluster</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Toronto_merged.loc[Toronto_merged['Cluster Labels'] == 0, Toronto_merged.columns[[0] + list(range(5, Toronto_merged.shape[1]))]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Toronto_merged.loc[Toronto_merged['Cluster Labels'] == 1, Toronto_merged.columns[[1] + list(range(5, Toronto_merged.shape[1]))]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Toronto_merged.loc[Toronto_merged['Cluster Labels'] == 2, Toronto_merged.columns[[2] + list(range(5, Toronto_merged.shape[1]))]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Toronto_merged.loc[Toronto_merged['Cluster Labels'] == 3, Toronto_merged.columns[[3] + list(range(5, Toronto_merged.shape[1]))]])"
   ]
  },
  {
   "source": [
    "<h2 align=\"center\">End of Notebook: Be kind when grading</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}